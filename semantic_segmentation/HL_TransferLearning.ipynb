{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d87cccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "from typing import Any, Dict, Type, cast\n",
    "from sharp_dataloader import GenMARSH, RandomRotation, Resize, gen_weights\n",
    "from torch.utils.data import DataLoader\n",
    "from os.path import dirname as up\n",
    "import pandas as pd\n",
    "import smp_metrics\n",
    "from torchmetrics import Accuracy, JaccardIndex, MetricCollection\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import numpy as np\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from MarshModel import MarshModel\n",
    "from torchvision import transforms\n",
    "import itertools \n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path_cur = os.path.abspath(os.getcwd())\n",
    "root_path = up(path_cur)\n",
    "data_path = os.path.join(root_path, 'data/HL_NAIP/HL_transferlearning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50d4b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(root_path)\n",
    "from utils import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e678cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Any, Dict, cast\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy, JaccardIndex, MetricCollection\n",
    "from sharp_trainer import SemanticSegmentationTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ffa2baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c52119a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/rapids/notebooks/sciclone/geograd/Miranda/github/MarshMapping'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8990ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([transforms.ToTensor(),\n",
    "                                RandomRotation([-90, 0, 90, 180]),\n",
    "                                Resize(512)])\n",
    "\n",
    "# load data\n",
    "dataset = GenMARSH(data_path, transform=transform_train, normalization=True, ndvi=True, datasource='NAIP')\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "trainloader = DataLoader(train_dataset, \n",
    "                batch_size = 8, \n",
    "                shuffle = True,\n",
    "                num_workers = 0,\n",
    "                pin_memory = False)\n",
    "\n",
    "testloader = DataLoader(test_dataset, \n",
    "                batch_size = 8, \n",
    "                shuffle = False,\n",
    "                num_workers = 0,\n",
    "                pin_memory = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbce67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def display_image(image, label):\n",
    "    \n",
    "    # reshape data\n",
    "    ndata = np.moveaxis(np.array(image), 0, -1)  # ndata is of shape (40, 40, 13)\n",
    "    # select RGB (or any other combination)\n",
    "    rgb = ndata[...,[2,1,0]]\n",
    "    \n",
    "    ndvi = ndata[..., -1]\n",
    "    \n",
    "    f = plt.figure()\n",
    "    f.add_subplot(1,3,1)\n",
    "    plt.imshow(rgb)\n",
    "    \n",
    "    f.add_subplot(1,3,2)\n",
    "    plt.imshow(label)\n",
    "    \n",
    "    f.add_subplot(1,3,3)\n",
    "    plt.imshow(ndvi)\n",
    "    plt.show(block=True)\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    sample = dataset[i]\n",
    "    display_image(**sample)\n",
    "\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7313e0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HLSegmentation_val_loss_unet_resnet50_0.0001_ce_imagenet\n",
      "HLSegmentation_val_loss_deeplabv3_resnet50_0.0001_ce_imagenet\n"
     ]
    }
   ],
   "source": [
    "monitor_options = ['val_loss']\n",
    "model_options = ['unet', 'deeplabv3'] #'unet', 'fpn', 'pspnet', 'deeplabv3', 'deeplabv3plus', 'pan', 'manet', 'linknet'\n",
    "encoder_options = ['resnet50']\n",
    "lr_options = [1e-4]\n",
    "loss_options = [\"ce\"]\n",
    "weight_init_options = [\"imagenet\"]\n",
    "in_channel = 5\n",
    "out_channel = 3\n",
    "\n",
    "# class_distr = torch.Tensor([0.02515424979261073, 0.9748457502073893])\n",
    "class_distr = torch.Tensor([0.744150945415795, 0.0064356910282143895, 0.24941336355599059]) # background, high marsh, low marsh\n",
    "weight = gen_weights(class_distr, c=1.03)\n",
    "\n",
    "\n",
    "for (model, encoder, lr, loss, weight_init, monitor_state) in itertools.product(\n",
    "        model_options,\n",
    "        encoder_options,\n",
    "        lr_options,\n",
    "        loss_options,\n",
    "        weight_init_options,\n",
    "        monitor_options):\n",
    "    \n",
    "    experiment_name = f\"HLSegmentation_{monitor_state}_{model}_{encoder}_{lr}_{loss}_{weight_init}\"\n",
    "    \n",
    "    print(experiment_name)\n",
    "\n",
    "    experiment_dir = os.path.join(root_path, experiment_name)\n",
    "    logger = TensorBoardLogger(experiment_dir, name=\"models\")\n",
    "    \n",
    "    if monitor_state == 'val_loss':\n",
    "        tracking_mode = 'min'\n",
    "    elif monitor_state == 'val_JaccardIndex':\n",
    "        tracking_mode = 'max'\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=monitor_state, dirpath=experiment_dir, save_top_k=1, save_last=True, mode=tracking_mode)\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(monitor=monitor_state, min_delta=0.00, patience=5, mode=tracking_mode)\n",
    "\n",
    "\n",
    "    model = SemanticSegmentationTask(\n",
    "                    segmentation_model=model,\n",
    "                    encoder_name=encoder,\n",
    "                    encoder_weights=weight_init,\n",
    "                    ignore_index = 0,\n",
    "                    c_weights = weight,\n",
    "                    monitor_state = monitor_state,\n",
    "                    learning_rate=lr,\n",
    "                    in_channels=in_channel,\n",
    "                    num_classes=out_channel,\n",
    "                    learning_rate_schedule_patience=6,\n",
    "                    loss=loss,\n",
    "                    imagenet_pretraining=True)\n",
    "\n",
    "#     trainer = pl.Trainer(\n",
    "#                 callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "#                 logger=logger,\n",
    "#                 default_root_dir=experiment_dir,\n",
    "#                 min_epochs=1,\n",
    "#                 max_epochs=100,\n",
    "#                 accelerator=\"gpu\",\n",
    "#                 devices=[2])\n",
    "\n",
    "#     trainer.fit(model, trainloader, testloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80be36d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for count,child in enumerate(model.children()):\n",
    "#     print(\" Child \", count , \"is -\")\n",
    "#     print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc6144fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  0  is frozen now\n",
      "0\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n",
      "Child  1  is frozen now\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for count_parents, parents in enumerate(model.children()):\n",
    "    \n",
    "    if count_parents == 0:\n",
    "        \n",
    "        for count_child, child in enumerate(parents.children()):\n",
    "            \n",
    "            if count_child == 2:\n",
    "                break\n",
    "            \n",
    "            for param in child.parameters():\n",
    "                param.requires_grad=False\n",
    "                print(\"Child \",count_child,\" is frozen now\")\n",
    "                print(count_child)\n",
    "        \n",
    "# #         if count==2:\n",
    "# #             break\n",
    "        \n",
    "# #         for param in child.parameters():\n",
    "# #             param.requires_grad=False\n",
    "# #             print(\"Child \",count,\" is frozen now\")\n",
    "# #             print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "540bf5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Child  0  is frozen now\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "Child  1  is frozen now\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Child  0  is frozen now\n",
      "ASPP(\n",
      "  (convs): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): ASPPConv(\n",
      "      (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): ASPPConv(\n",
      "      (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (3): ASPPConv(\n",
      "      (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (4): ASPPPooling(\n",
      "      (0): AdaptiveAvgPool2d(output_size=1)\n",
      "      (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (project): Sequential(\n",
      "    (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      ")\n",
      "Child  1  is frozen now\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "Child  0  is frozen now\n",
      "Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "Child  1  is frozen now\n",
      "UpsamplingBilinear2d(scale_factor=8.0, mode=bilinear)\n"
     ]
    }
   ],
   "source": [
    "model_unet = smp.DeepLabV3(\"resnet50\")\n",
    "for parents in model_unet.children():\n",
    "    for count, child in enumerate(parents.children()):\n",
    "        if count==2:\n",
    "            break\n",
    "        \n",
    "        for param in child.parameters():\n",
    "            param.requires_grad=False\n",
    "        \n",
    "        print(\"Child \",count,\" is frozen now\")\n",
    "        print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d01f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed192f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acf76b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481946fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce85a429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c8311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb41f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d6277e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93818411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e14c57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vims",
   "language": "python",
   "name": "vims"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
