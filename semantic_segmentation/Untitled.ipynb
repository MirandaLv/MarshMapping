{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8976a312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "from typing import Any, Dict, Type, cast\n",
    "from sharp_dataloader import GenMARSH\n",
    "from torch.utils.data import DataLoader\n",
    "from os.path import dirname as up\n",
    "import pandas as pd\n",
    "import smp_metrics\n",
    "from torchmetrics import Accuracy, JaccardIndex, MetricCollection\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import numpy as np\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from MarshModel import MarshModel\n",
    "from torchvision import transforms\n",
    "import itertools \n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "path_cur = os.path.abspath(os.getcwd())\n",
    "root_path = up(path_cur)\n",
    "data_dir = os.path.join(root_path, 'data', 'NAIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2e55d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(root_path)\n",
    "from utils import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab4f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tmi_file = os.path.join(data_dir, 'NAIP_data_highlow_50000.csv') #NAIP_data_highlow_512.csv\n",
    "# df = pd.read_csv(tmi_file)\n",
    "\n",
    "# data_transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Resize((512, 512))])\n",
    "\n",
    "# dataset = GenMARSH(tmi_file, transform=None, normalization=True, ndvi=False, ndwi=False, datasource='naip')\n",
    "\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "# train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "# # train_transform = transforms.Compose([\n",
    "# #     transforms.ToTensor(),\n",
    "# #     transforms.Resize((512, 512))])\n",
    "\n",
    "# # test_transform = transforms.Compose([\n",
    "# #     transforms.ToTensor(),\n",
    "# #     transforms.Resize((512, 512))])\n",
    "\n",
    "\n",
    "# trainloader = DataLoader(train_dataset, \n",
    "#                 batch_size = 32, \n",
    "#                 shuffle = True,\n",
    "#                 num_workers = 0,\n",
    "#                 pin_memory = False)\n",
    "\n",
    "# testloader = DataLoader(test_dataset,\n",
    "#                 batch_size = ,\n",
    "#                 shuffle = False,\n",
    "#                 num_workers = 0,\n",
    "#                 pin_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61db5995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get some random training images\n",
    "# dataiter = iter(trainloader)\n",
    "# batch = dataiter.next()\n",
    "# batch['label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90166b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(image, label):\n",
    "\n",
    "    rgb_img = np.stack((image[2,:,:], image[1,:,:], image[0,:,:]), axis=2).astype(np.uint8)\n",
    "    gray_img = image[0,:,:][:, :,np.newaxis]\n",
    "    \n",
    "    label = np.transpose(label, (1,2,0))\n",
    "    \n",
    "    f = plt.figure()\n",
    "    f.add_subplot(1,2,1)\n",
    "    plt.imshow(rgb_img)\n",
    "    \n",
    "    f.add_subplot(1,2,2)\n",
    "    plt.imshow(gray_img)\n",
    "\n",
    "    plt.show(block=True)\n",
    "    \n",
    "\n",
    "def display_NAIP(image, label):\n",
    "    \n",
    "    # reshape data\n",
    "    ndata = np.moveaxis(image, 0, -1)  # ndata is of shape (40, 40, 13)\n",
    "    # select RGB (or any other combination)\n",
    "    rgb = ndata[...,[2,1,0]]\n",
    "    \n",
    "#     nlabel = np.moveaxis(label, 0, -1)\n",
    "    \n",
    "    f = plt.figure()\n",
    "    f.add_subplot(1,2,1)\n",
    "    plt.imshow(rgb)\n",
    "    \n",
    "    f.add_subplot(1,2,2)\n",
    "    plt.imshow(label)\n",
    "    plt.show(block=True)\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    sample = dataset[i]\n",
    "    display_NAIP(**sample)\n",
    "\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0f253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Any, Dict, cast\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy, JaccardIndex, MetricCollection\n",
    "from sharp_trainer import SemanticSegmentationTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d87a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f0383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c412c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = OmegaConf.load(\"./test_multiclass.yaml\")\n",
    "conf_dict = OmegaConf.to_object(conf.experiment)\n",
    "conf_dict = cast(Dict[Any, Dict[Any, Any]], conf_dict)\n",
    "\n",
    "# prepare data for training\n",
    "dl_kwargs = conf_dict[\"dataloader\"]\n",
    "label_file = dl_kwargs[\"labelpath\"]\n",
    "\n",
    "# load data\n",
    "dataset = GenMARSH(label_file, transform=None, normalization=dl_kwargs['normalization'], ndvi=dl_kwargs['ndvi'], ndwi=dl_kwargs['ndwi'], datasource=dl_kwargs['datasource'])\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "trainloader = DataLoader(train_dataset, \n",
    "                batch_size = dl_kwargs[\"batch_size\"], \n",
    "                shuffle = True,\n",
    "                num_workers = dl_kwargs[\"num_workers\"],\n",
    "                pin_memory = False)\n",
    "\n",
    "testloader = DataLoader(test_dataset, \n",
    "                batch_size = dl_kwargs[\"batch_size\"], \n",
    "                shuffle = False,\n",
    "                num_workers = dl_kwargs[\"num_workers\"],\n",
    "                pin_memory = False)\n",
    "\n",
    "# # Setup model\n",
    "# model_kwargs = conf_dict['module']\n",
    "    \n",
    "# experiment_folder = \"{}_{}_{}_{}_{}_{}\".format(model_kwargs['segmentation_model'], model_kwargs['encoder_name'], model_kwargs['learning_rate'], model_kwargs['in_channels'], model_kwargs['loss'], dl_kwargs['tracker_val'])\n",
    "\n",
    "    \n",
    "# experiment_dir = os.path.join(root_path, 'outputs_combined',experiment_folder)\n",
    "# logger = TensorBoardLogger(experiment_dir, name=\"models\")\n",
    "    \n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "# monitor=dl_kwargs['tracker_val'], dirpath=experiment_dir, save_top_k=1, save_last=True, mode=dl_kwargs['tracker_mode'])\n",
    "    \n",
    "# early_stopping_callback = EarlyStopping(monitor=dl_kwargs['tracker_val'], min_delta=0.00, patience=5, mode=dl_kwargs['tracker_mode'])\n",
    "    \n",
    "\n",
    "# model = SemanticSegmentationTask(**model_kwargs)\n",
    "    \n",
    "# trainer = pl.Trainer(\n",
    "#             callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "#             logger=logger,\n",
    "#             default_root_dir=experiment_dir,\n",
    "#             min_epochs=1,\n",
    "#             max_epochs=100,\n",
    "#             accelerator=\"gpu\",\n",
    "#             devices=[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c917668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_options = ['val_JaccardIndex']\n",
    "model_options = ['unet', 'fpn', 'pspnet', 'deeplabv3', 'deeplabv3plus', 'pan', 'manet', 'linknet']\n",
    "encoder_options = ['vgg11']\n",
    "lr_options = [1e-4]\n",
    "loss_options = [\"ce\"]\n",
    "weight_init_options = [\"imagenet\"]\n",
    "in_channel = 4\n",
    "out_channel = 3\n",
    "\n",
    "for (model, encoder, lr, loss, weight_init, monitor_state) in itertools.product(\n",
    "        model_options,\n",
    "        encoder_options,\n",
    "        lr_options,\n",
    "        loss_options,\n",
    "        weight_init_options,\n",
    "        monitor_options):\n",
    "    \n",
    "    experiment_name = f\"{monitor_state}_{model}_{encoder}_{lr}_{loss}_{weight_init}\"\n",
    "    \n",
    "    print(experiment_name)\n",
    "\n",
    "    experiment_dir = os.path.join(dl_kwargs[\"out_dir\"], experiment_name)\n",
    "    logger = TensorBoardLogger(experiment_dir, name=\"models\")\n",
    "    \n",
    "    if monitor_state == 'val_loss':\n",
    "        tracking_mode = 'min'\n",
    "    elif monitor_state == 'val_JaccardIndex':\n",
    "        tracking_mode = 'max'\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=monitor_state, dirpath=experiment_dir, save_top_k=1, save_last=True, mode=tracking_mode)\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(monitor=monitor_state, min_delta=0.00, patience=5, mode=tracking_mode)\n",
    "\n",
    "\n",
    "    model = SemanticSegmentationTask(\n",
    "                    segmentation_model=model,\n",
    "                    encoder_name=encoder,\n",
    "                    encoder_weights=weight_init,\n",
    "                    learning_rate=lr,\n",
    "                    in_channels=in_channel,\n",
    "                    num_classes=out_channel,\n",
    "                    learning_rate_schedule_patience=6,\n",
    "                    ignore_index=0,\n",
    "                    loss=loss,\n",
    "                    imagenet_pretraining=True)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "                callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "                logger=logger,\n",
    "                default_root_dir=experiment_dir,\n",
    "                min_epochs=1,\n",
    "                max_epochs=100,\n",
    "                accelerator=\"gpu\",\n",
    "                devices=[3])\n",
    "\n",
    "    trainer.fit(model, trainloader, testloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fdf19e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22acd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "\n",
    "for m in all_model_path:\n",
    "    \n",
    "    model_name = os.path.basename(options[\"model_path\"])\n",
    "        \n",
    "    if \"CW\" in model_name: # and \"deeplabv3+\" not in model_name\n",
    "        model = SemanticSegmentation.load_from_checkpoint(options[\"model_path\"])\n",
    "        model.eval()\n",
    "    else:\n",
    "        model = SemanticSegmentationTask.load_from_checkpoint(options[\"model_path\"])\n",
    "        model.eval()\n",
    "    \n",
    "    \n",
    "    \n",
    "    y_true = []\n",
    "    y_predicted = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"testing\"):\n",
    "            \n",
    "            image = batch[\"image\"]\n",
    "            target = batch[\"mask\"]\n",
    "\n",
    "            logits = model(image) # predicted\n",
    "            logits = torch.nn.functional.softmax(logits, dim=1).argmax(1)\n",
    "            \n",
    "            logits = logits.reshape(-1)\n",
    "            target = target.reshape(-1)\n",
    "\n",
    "            # Accuracy metrics only on annotated pixels (Check on the dimension changes)\n",
    "\n",
    "            mask = target != 0 # 0 is the background\n",
    "            \n",
    "            logits = logits[mask]\n",
    "            target = target[mask]\n",
    "\n",
    "            y_predicted += logits.tolist()\n",
    "            y_true += target.tolist()\n",
    "            \n",
    "        \n",
    "        ####################################################################\n",
    "        # Save Scores to the .log file                                     #\n",
    "        ####################################################################\n",
    "        acc = Evaluation(y_predicted, y_true)\n",
    "        logging.info(\"\\n\")\n",
    "        logging.info(\"STATISTICS: \\n\")\n",
    "        logging.info(\"Evaluation: \" + str(acc))\n",
    "        print(\"Evaluation: \" + str(acc))\n",
    "        \"\"\"\n",
    "        Confusion matrix whose i-th row and j-th column entry indicates the number of samples with true label \n",
    "        You being i-th class and predicted label being j-th class.\n",
    "        \"\"\"\n",
    "        conf_mat = confusion_matrix(y_true, y_predicted, options['labels'])\n",
    "        \n",
    "        logging.info(\"Confusion Matrix:  \\n\" + str(conf_mat.to_string()))\n",
    "        print(\"Confusion Matrix:  \\n\" + str(conf_mat.to_string()))\n",
    " \n",
    "\n",
    "        if options['predict_masks']:\n",
    "            \n",
    "            path = os.path.join(up(up(root_path)), 'VIMS', 'NAIP', 'VA_NAIP_2018_8977', 'test')\n",
    "            ROIs = [file for file in os.listdir(path) if file.split('.')[-1]=='tif']\n",
    "\n",
    "            impute_nan = np.tile(bands_mean, (256,256,1))\n",
    "                        \n",
    "            for roi in tqdm(ROIs):\n",
    "                \n",
    "                roi_file = os.path.join(path, roi)\n",
    "                os.makedirs(options['gen_masks_path'], exist_ok=True)\n",
    "            \n",
    "                output_image = os.path.join(options['gen_masks_path'], os.path.basename(roi_file).split('.tif')[0] + '_unet.tif')\n",
    "            \n",
    "                # Read metadata of the initial image\n",
    "                with rasterio.open(roi_file, mode ='r') as src:\n",
    "                    tags = src.tags().copy()\n",
    "                    meta = src.meta\n",
    "                    image = src.read()\n",
    "                    image = np.moveaxis(image, (0, 1, 2), (2, 0, 1)).astype('float32')\n",
    "                    dtype = src.read(1).dtype\n",
    "            \n",
    "                # Update meta to reflect the number of layers\n",
    "                meta.update(count = 1)\n",
    "            \n",
    "                # Write it\n",
    "                with rasterio.open(output_image, 'w', **meta) as dst:\n",
    "                    \n",
    "                    # Preprocessing before prediction\n",
    "                    nan_mask = np.isnan(image)\n",
    "                    image[nan_mask] = impute_nan[nan_mask]\n",
    "                \n",
    "                    image = transform_test(image)\n",
    "                    image = standardization(image)\n",
    "\n",
    "                    # Predictions\n",
    "                    logits = model(image.unsqueeze(0))\n",
    "                    probs = logits.softmax(dim=1).numpy().argmax(1).squeeze()\n",
    "                    \n",
    "                    # Write the mask with georeference\n",
    "                    dst.write_band(1, probs.astype(dtype).copy()) # In order to be in the same dtype\n",
    "                    dst.update_tags(**tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b281082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, \n",
    "#                 batch_size = 32, \n",
    "#                 shuffle = False,\n",
    "#                 num_workers = 0,\n",
    "#                 pin_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c33c187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on val_loss_unet_resnet34_0.0001_ce_imagenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/vims/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: {'macroPrec': 0.566304097919645, 'microPrec': 0.8293311534970461, 'weightPrec': 0.8404754306820365, 'macroRec': 0.535295625234375, 'microRec': 0.8293311534970461, 'weightRec': 0.8293311534970461, 'macroF1': 0.5424538093465939, 'microF1': 0.8293311534970461, 'weightF1': 0.8235116657150688, 'subsetAcc': 0.8293311534970461, 'IoU': 0.45960843576501365}\n",
      "Confusion Matrix:  \n",
      "           Background   high_marsh   low_marsh         Sum Recall\n",
      "Background        0.0          0.0         0.0         0.0    0.0\n",
      "high_marsh    33747.0   83188337.0   4491075.0  87713159.0   0.95\n",
      "low_marsh     13977.0   20803931.0  39959595.0  60777503.0   0.66\n",
      "Sum           47724.0  103992268.0  44450670.0        mPA:   0.54\n",
      "IoU               0.0         0.77        0.61       mIoU:   0.46\n",
      "Precision         0.0          0.8         0.9         OA:   0.83\n",
      "F1-score          0.0         0.87        0.76   F1-macro:   0.54\n",
      "time spent: 4012.466364622116\n",
      "Working on val_JaccardIndex_unet_resnet34_0.0001_ce_imagenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/vims/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: {'macroPrec': 0.5674981404532025, 'microPrec': 0.8350018737205172, 'weightPrec': 0.8435777712763692, 'macroRec': 0.5406207229525092, 'microRec': 0.8350018737205172, 'weightRec': 0.8350018737205172, 'macroF1': 0.5474199761814894, 'microF1': 0.8350018737205172, 'weightF1': 0.8301987693809911, 'subsetAcc': 0.8350018737205172, 'IoU': 0.46639772467803065}\n",
      "Confusion Matrix:  \n",
      "           Background   high_marsh   low_marsh         Sum Recall\n",
      "Background        0.0          0.0         0.0         0.0    0.0\n",
      "high_marsh    32597.0   82768622.0   4911940.0  87713159.0   0.94\n",
      "low_marsh     10824.0   19545320.0  41221359.0  60777503.0   0.68\n",
      "Sum           43421.0  102313942.0  46133299.0        mPA:   0.54\n",
      "IoU               0.0         0.77        0.63       mIoU:   0.47\n",
      "Precision         0.0         0.81        0.89         OA:   0.84\n",
      "F1-score          0.0         0.87        0.77   F1-macro:   0.55\n",
      "time spent: 3984.156114578247\n",
      "Working on val_JaccardIndex_fpn_resnet34_0.0001_ce_imagenet\n",
      "Evaluation: {'macroPrec': 0.8507793151148857, 'microPrec': 0.8407724386062742, 'weightPrec': 0.8454713800531751, 'macroRec': 0.8202946111742215, 'microRec': 0.8407724386062742, 'weightRec': 0.8407724386062742, 'macroF1': 0.8290667924637249, 'microF1': 0.8407724386062742, 'weightF1': 0.837180873305623, 'subsetAcc': 0.8407724386062742, 'IoU': 0.7105356139066453}\n",
      "Confusion Matrix:  \n",
      "            high_marsh   low_marsh         Sum Recall\n",
      "high_marsh  81852570.0   5860589.0  87713159.0   0.93\n",
      "low_marsh   17783217.0  42994286.0  60777503.0   0.71\n",
      "Sum         99635787.0  48854875.0        mPA:   0.82\n",
      "IoU               0.78        0.65       mIoU:   0.71\n",
      "Precision         0.82        0.88         OA:   0.84\n",
      "F1-score          0.87        0.78   F1-macro:   0.83\n",
      "time spent: 3021.9798147678375\n",
      "Working on val_loss_fpn_resnet34_0.0001_ce_imagenet\n",
      "Evaluation: {'macroPrec': 0.8531805555892134, 'microPrec': 0.8360658126771635, 'weightPrec': 0.8450799013398971, 'macroRec': 0.8115577118634679, 'microRec': 0.8360658126771635, 'weightRec': 0.8360658126771635, 'macroF1': 0.8218676883976912, 'microF1': 0.8360658126771635, 'weightF1': 0.830990217385896, 'subsetAcc': 0.8360658126771635, 'IoU': 0.7007011392422754}\n",
      "Confusion Matrix:  \n",
      "             high_marsh   low_marsh         Sum Recall\n",
      "high_marsh   83035045.0   4678114.0  87713159.0   0.95\n",
      "low_marsh    19664582.0  41112921.0  60777503.0   0.68\n",
      "Sum         102699627.0  45791035.0        mPA:   0.81\n",
      "IoU                0.77        0.63       mIoU:    0.7\n",
      "Precision          0.81         0.9         OA:   0.84\n",
      "F1-score           0.87        0.77   F1-macro:   0.82\n",
      "time spent: 3021.1768450737\n",
      "Working on val_loss_pspnet_resnet34_0.0001_ce_imagenet\n",
      "Evaluation: {'macroPrec': 0.8528426437315019, 'microPrec': 0.8300991613869968, 'weightPrec': 0.842855481452258, 'macroRec': 0.8025893725454017, 'microRec': 0.8300991613869968, 'weightRec': 0.8300991613869968, 'macroF1': 0.8136330671045277, 'microF1': 0.8300991613869969, 'weightF1': 0.8236817268602251, 'subsetAcc': 0.8300991613869968, 'IoU': 0.6895027367940034}\n",
      "Confusion Matrix:  \n",
      "             high_marsh   low_marsh         Sum Recall\n",
      "high_marsh   83699853.0   4013306.0  87713159.0   0.95\n",
      "low_marsh    21215382.0  39562121.0  60777503.0   0.65\n",
      "Sum         104915235.0  43575427.0        mPA:    0.8\n",
      "IoU                0.77        0.61       mIoU:   0.69\n",
      "Precision           0.8        0.91         OA:   0.83\n",
      "F1-score           0.87        0.76   F1-macro:   0.81\n",
      "time spent: 2969.799395084381\n",
      "Working on val_JaccardIndex_pspnet_resnet34_0.0001_ce_imagenet\n",
      "Evaluation: {'macroPrec': 0.8493520493076514, 'microPrec': 0.8383276047351719, 'weightPrec': 0.8436355044095998, 'macroRec': 0.817030854777778, 'microRec': 0.8383276047351719, 'weightRec': 0.8383276047351719, 'macroF1': 0.8260560018502995, 'microF1': 0.838327604735172, 'weightF1': 0.834436769186175, 'subsetAcc': 0.8383276047351719, 'IoU': 0.7063016258423147}\n",
      "Confusion Matrix:  \n",
      "             high_marsh   low_marsh         Sum Recall\n",
      "high_marsh   81962281.0   5750878.0  87713159.0   0.93\n",
      "low_marsh    18255963.0  42521540.0  60777503.0    0.7\n",
      "Sum         100218244.0  48272418.0        mPA:   0.82\n",
      "IoU                0.77        0.64       mIoU:   0.71\n",
      "Precision          0.82        0.88         OA:   0.84\n",
      "F1-score           0.87        0.78   F1-macro:   0.83\n",
      "time spent: 2972.658809900284\n",
      "Working on val_loss_deeplabv3_resnet34_0.0001_ce_imagenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/vims/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: {'macroPrec': 0.4982090957084126, 'microPrec': 0.7475491017744941, 'weightPrec': 0.7633897539700398, 'macroRec': 0.503485425247123, 'microRec': 0.7475491017744941, 'weightRec': 0.7475491017744941, 'macroF1': 0.4970109392636159, 'microF1': 0.7475491017744941, 'weightF1': 0.7498722333798747, 'subsetAcc': 0.7475491017744941, 'IoU': 0.396577247784992}\n",
      "Confusion Matrix:  \n",
      "           Background  high_marsh   low_marsh         Sum Recall\n",
      "Background        0.0         0.0         0.0         0.0    0.0\n",
      "high_marsh    65397.0  62530291.0  25117471.0  87713159.0   0.71\n",
      "low_marsh     31468.0  12272265.0  48473770.0  60777503.0    0.8\n",
      "Sum           96865.0  74802556.0  73591241.0        mPA:    0.5\n",
      "IoU               0.0        0.63        0.56       mIoU:    0.4\n",
      "Precision         0.0        0.84        0.66         OA:   0.75\n",
      "F1-score          0.0        0.77        0.72   F1-macro:    0.5\n",
      "time spent: 4069.856399536133\n",
      "Working on val_JaccardIndex_deeplabv3_resnet34_0.0001_ce_imagenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/vims/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: {'macroPrec': 0.5548416852259986, 'microPrec': 0.8352166683720489, 'weightPrec': 0.8345691476522855, 'macroRec': 0.5497426103908231, 'microRec': 0.8352166683720489, 'weightRec': 0.8352166683720489, 'macroF1': 0.551852714928078, 'microF1': 0.8352166683720489, 'weightF1': 0.8342771916879946, 'subsetAcc': 0.8352166683720489, 'IoU': 0.4718385959766837}\n",
      "Confusion Matrix:  \n",
      "           Background  high_marsh   low_marsh         Sum Recall\n",
      "Background        0.0         0.0         0.0         0.0    0.0\n",
      "high_marsh     3659.0  77456393.0  10253107.0  87713159.0   0.88\n",
      "low_marsh      1704.0  14210316.0  46565483.0  60777503.0   0.77\n",
      "Sum            5363.0  91666709.0  56818590.0        mPA:   0.55\n",
      "IoU               0.0        0.76        0.66       mIoU:   0.47\n",
      "Precision         0.0        0.84        0.82         OA:   0.84\n",
      "F1-score          0.0        0.86        0.79   F1-macro:   0.55\n",
      "time spent: 4172.602785587311\n",
      "Working on val_loss_pan_resnet34_0.0001_ce_imagenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/vims/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: {'macroPrec': 0.5591011341799936, 'microPrec': 0.83352899995826, 'weightPrec': 0.8357086888213178, 'macroRec': 0.5435111319385949, 'microRec': 0.83352899995826, 'weightRec': 0.83352899995826, 'macroF1': 0.548377806075798, 'microF1': 0.83352899995826, 'weightF1': 0.8305668641747832, 'subsetAcc': 0.83352899995826, 'IoU': 0.4673310556851264}\n",
      "Confusion Matrix:  \n",
      "           Background  high_marsh   low_marsh         Sum Recall\n",
      "Background        0.0         0.0         0.0         0.0    0.0\n",
      "high_marsh       40.0  80340251.0   7372868.0  87713159.0   0.92\n",
      "low_marsh         3.0  17346478.0  43431022.0  60777503.0   0.71\n",
      "Sum              43.0  97686729.0  50803890.0        mPA:   0.54\n",
      "IoU               0.0        0.76        0.64       mIoU:   0.47\n",
      "Precision         0.0        0.82        0.85         OA:   0.83\n",
      "F1-score          0.0        0.87        0.78   F1-macro:   0.55\n",
      "time spent: 4070.162744283676\n",
      "Working on val_JaccardIndex_deeplabv3plus_resnet34_0.0001_ce_imagenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/vims/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: {'macroPrec': 0.5664528533001097, 'microPrec': 0.8364621945048639, 'weightPrec': 0.8430826394738385, 'macroRec': 0.5425542606982288, 'microRec': 0.8364621945048639, 'weightRec': 0.8364621945048639, 'macroF1': 0.5489051575910322, 'microF1': 0.8364621945048639, 'weightF1': 0.8320855981904217, 'subsetAcc': 0.8364621945048639, 'IoU': 0.4683992878807984}\n",
      "Confusion Matrix:  \n",
      "           Background   high_marsh   low_marsh         Sum Recall\n",
      "Background        0.0          0.0         0.0         0.0    0.0\n",
      "high_marsh      213.0   82326720.0   5386226.0  87713159.0   0.94\n",
      "low_marsh       257.0   18897141.0  41880105.0  60777503.0   0.69\n",
      "Sum             470.0  101223861.0  47266331.0        mPA:   0.54\n",
      "IoU               0.0         0.77        0.63       mIoU:   0.47\n",
      "Precision         0.0         0.81        0.89         OA:   0.84\n",
      "F1-score          0.0         0.87        0.78   F1-macro:   0.55\n",
      "time spent: 4058.8212430477142\n",
      "Working on val_loss_manet_resnet34_0.0001_ce_imagenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/vims/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: {'macroPrec': 0.5753273163798, 'microPrec': 0.8564730285868077, 'weightPrec': 0.8591557504315782, 'macroRec': 0.5598036872611439, 'microRec': 0.8564730285868077, 'weightRec': 0.8564730285868077, 'macroF1': 0.5648858776495803, 'microF1': 0.8564730285868076, 'weightF1': 0.8541072367199131, 'subsetAcc': 0.8564730285868077, 'IoU': 0.4912837676425008}\n",
      "Confusion Matrix:  \n",
      "           Background  high_marsh   low_marsh         Sum Recall\n",
      "Background        0.0         0.0         0.0         0.0    0.0\n",
      "high_marsh      156.0  81761054.0   5951949.0  87713159.0   0.93\n",
      "low_marsh       463.0  15359847.0  45417193.0  60777503.0   0.75\n",
      "Sum             619.0  97120901.0  51369142.0        mPA:   0.56\n",
      "IoU               0.0        0.79        0.68       mIoU:   0.49\n",
      "Precision         0.0        0.84        0.88         OA:   0.86\n",
      "F1-score          0.0        0.88        0.81   F1-macro:   0.56\n",
      "time spent: 4098.592904090881\n",
      "Working on val_JaccardIndex_pan_resnet34_0.0001_ce_imagenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/vims/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: {'macroPrec': 0.5576751059175762, 'microPrec': 0.8311718416340551, 'weightPrec': 0.8334793845428095, 'macroRec': 0.5416677323566632, 'microRec': 0.8311718416340551, 'weightRec': 0.8311718416340551, 'macroF1': 0.5465920198892328, 'microF1': 0.8311718416340551, 'weightF1': 0.8280663371646517, 'subsetAcc': 0.8311718416340551, 'IoU': 0.4648211065653625}\n",
      "Confusion Matrix:  \n",
      "           Background  high_marsh   low_marsh         Sum Recall\n",
      "Background        0.0         0.0         0.0         0.0    0.0\n",
      "high_marsh        0.0  80294973.0   7418186.0  87713159.0   0.92\n",
      "low_marsh       511.0  17650708.0  43126284.0  60777503.0   0.71\n",
      "Sum             511.0  97945681.0  50544470.0        mPA:   0.54\n",
      "IoU               0.0        0.76        0.63       mIoU:   0.46\n",
      "Precision         0.0        0.82        0.85         OA:   0.83\n",
      "F1-score          0.0        0.86        0.77   F1-macro:   0.55\n",
      "time spent: 4063.6595420837402\n",
      "Working on val_JaccardIndex_manet_resnet34_0.0001_ce_imagenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/vims/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: {'macroPrec': 0.5667798910874811, 'microPrec': 0.8450968721521357, 'weightPrec': 0.847205337394944, 'macroRec': 0.5521249759513932, 'microRec': 0.8450968721521357, 'weightRec': 0.8450968721521357, 'macroF1': 0.5569233495642137, 'microF1': 0.8450968721521357, 'weightF1': 0.8426492983532186, 'subsetAcc': 0.8450968721521357, 'IoU': 0.47955912916930216}\n",
      "Confusion Matrix:  \n",
      "           Background  high_marsh   low_marsh         Sum Recall\n",
      "Background        0.0         0.0         0.0         0.0    0.0\n",
      "high_marsh    12354.0  80819388.0   6881417.0  87713159.0   0.92\n",
      "low_marsh      1458.0  16106439.0  44669606.0  60777503.0   0.73\n",
      "Sum           13812.0  96925827.0  51551023.0        mPA:   0.55\n",
      "IoU               0.0        0.78        0.66       mIoU:   0.48\n",
      "Precision         0.0        0.83        0.87         OA:   0.85\n",
      "F1-score          0.0        0.88         0.8   F1-macro:   0.56\n",
      "time spent: 4129.781400918961\n",
      "Working on val_loss_linknet_resnet34_0.0001_ce_imagenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/vims/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: {'macroPrec': 0.5528686138986337, 'microPrec': 0.8336570484142632, 'weightPrec': 0.8331398576744077, 'macroRec': 0.5501467515575827, 'microRec': 0.8336570484142632, 'weightRec': 0.8336570484142632, 'macroF1': 0.5513728355334137, 'microF1': 0.8336570484142632, 'weightF1': 0.8332090339492452, 'subsetAcc': 0.8336570484142632, 'IoU': 0.47102777839779525}\n",
      "Confusion Matrix:  \n",
      "           Background  high_marsh   low_marsh         Sum Recall\n",
      "Background        0.0         0.0         0.0         0.0    0.0\n",
      "high_marsh    15534.0  76462290.0  11235335.0  87713159.0   0.87\n",
      "low_marsh      4304.0  13445202.0  47327997.0  60777503.0   0.78\n",
      "Sum           19838.0  89907492.0  58563332.0        mPA:   0.55\n",
      "IoU               0.0        0.76        0.66       mIoU:   0.47\n",
      "Precision         0.0        0.85        0.81         OA:   0.83\n",
      "F1-score          0.0        0.86        0.79   F1-macro:   0.55\n",
      "time spent: 4136.297409534454\n",
      "Working on val_JaccardIndex_linknet_resnet34_0.0001_ce_imagenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/vims/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: {'macroPrec': 0.5699309873414621, 'microPrec': 0.8444775537467804, 'weightPrec': 0.8494330619481846, 'macroRec': 0.5495359382387633, 'microRec': 0.8444775537467804, 'weightRec': 0.8444775537467804, 'macroF1': 0.5554897650777636, 'microF1': 0.8444775537467804, 'weightF1': 0.8411125949182807, 'subsetAcc': 0.8444775537467804, 'IoU': 0.4776792884034912}\n",
      "Confusion Matrix:  \n",
      "           Background  high_marsh   low_marsh         Sum Recall\n",
      "Background        0.0         0.0         0.0         0.0    0.0\n",
      "high_marsh    25110.0  82057153.0   5630896.0  87713159.0   0.94\n",
      "low_marsh      4765.0  17432860.0  43339878.0  60777503.0   0.71\n",
      "Sum           29875.0  99490013.0  48970774.0        mPA:   0.55\n",
      "IoU               0.0        0.78        0.65       mIoU:   0.48\n",
      "Precision         0.0        0.82        0.89         OA:   0.84\n",
      "F1-score          0.0        0.88        0.79   F1-macro:   0.56\n",
      "time spent: 4064.5265328884125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for m in os.listdir(os.path.join(root_path, 'outputs')):\n",
    "    if not m.endswith('ipynb_checkpoints'):\n",
    "        print(\"Working on {}\".format(m))\n",
    "        start_time = time.time()\n",
    "        mpath = os.path.join(root_path, 'outputs', m, 'last.ckpt')\n",
    "        model_load = SemanticSegmentationTask.load_from_checkpoint(mpath)\n",
    "        model_load.eval()\n",
    "        \n",
    "        y_true = []\n",
    "        y_predicted = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            for batch in testloader:\n",
    "\n",
    "                image = batch[\"image\"]\n",
    "                target = batch[\"label\"]\n",
    "\n",
    "                logits = model_load(image) # predicted\n",
    "                logits = torch.nn.functional.softmax(logits, dim=1).argmax(1)\n",
    "\n",
    "                logits = logits.reshape(-1)\n",
    "                target = target.reshape(-1)\n",
    "\n",
    "                # Accuracy metrics only on annotated pixels (Check on the dimension changes)\n",
    "\n",
    "                mask = target != 0 # 0 is the background\n",
    "                logits = logits[mask]\n",
    "                target = target[mask]\n",
    "\n",
    "                y_predicted += logits.tolist()\n",
    "                y_true += target.tolist()\n",
    "        \n",
    "        acc = metrics.Evaluation(y_predicted, y_true)\n",
    "        print(\"Evaluation: \" + str(acc))\n",
    "        \"\"\"\n",
    "        Confusion matrix whose i-th row and j-th column entry indicates the number of samples with true label \n",
    "        You being i-th class and predicted label being j-th class.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            test_labels = ['high_marsh', 'low_marsh']\n",
    "            conf_mat = metrics.confusion_matrix(y_true, y_predicted, test_labels)\n",
    "            print(\"Confusion Matrix:  \\n\" + str(conf_mat.to_string()))\n",
    "        except:\n",
    "            labels = ['Background', 'high_marsh', 'low_marsh']\n",
    "            conf_mat = metrics.confusion_matrix(y_true, y_predicted, labels)\n",
    "            print(\"Confusion Matrix:  \\n\" + str(conf_mat.to_string()))\n",
    "            \n",
    "\n",
    "        end_time = time.time()\n",
    "        time_diff = end_time - start_time\n",
    "        print(\"time spent: {}\".format(time_diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10e8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a6a2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ae2c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a565cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad58b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vims",
   "language": "python",
   "name": "vims"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
